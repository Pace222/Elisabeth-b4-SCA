{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpa_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elisabeth-b4 - Filter block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attacking the filter S-boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_path = \"..\\\\acquisition\\\\carto_eB4-Rnd-3-WhiteningAndFullFilter-1_key_256000_samples_full_filter\\\\carto_eB4-Rnd-3-WhiteningAndFullFilter-Alternating-Same-And-Varying-Seeds.mat\"\n",
    "key_path = \"..\\\\acquisition\\\\carto_eB4-Rnd-3-WhiteningAndFullFilter-1_key_256000_samples_full_filter\\\\carto_eB4-Rnd-3-WhiteningAndFullFilter-Alternating-Same-And-Varying-Seeds.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds, traces, real_keys = load_data(traces_path, key_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"correlation_locations_b4_two_last_rounds_hw_x_i.pic\", \"rb\") as r:\n",
    "    hw_x_i_locations = pic.load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_locations_and_hypotheses(funs_hypotheses: List[Callable], total_seeds: np.ndarray) -> np.ndarray:\n",
    "    hypotheses = np.zeros((KEY_WIDTH_B4, len(funs_hypotheses), 16, total_seeds.shape[0]), dtype=int)\n",
    "\n",
    "    for i, iv in enumerate(total_seeds):\n",
    "        indices, whitening = chacha_random_b4(iv)\n",
    "        for keyround_target_idx in range(KEYROUND_WIDTH_B4):\n",
    "            round_idx = keyround_target_idx // BLOCK_WIDTH_B4\n",
    "            block_idx = keyround_target_idx % BLOCK_WIDTH_B4\n",
    "    \n",
    "            for l, fun_hypo in enumerate(funs_hypotheses):\n",
    "                for k in range(16):\n",
    "                    hyp = fun_hypo(round_idx, block_idx, k, whitening)\n",
    "                    if hyp is not None:\n",
    "                        hypotheses[indices[keyround_target_idx], l, k, i] = hyp\n",
    "\n",
    "    return hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp_even_sbox_output(round_idx: int, block_idx: int, k: int, whitening: List[int]) -> int:\n",
    "    if block_idx == 6 or block_idx % 2 != 0:\n",
    "        return None\n",
    "    return HW[s_boxes_b4[block_idx][(k + whitening[round_idx * BLOCK_WIDTH_B4 + block_idx]) % 16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyp_hw_x_i(round_idx: int, block_idx: int, k: int, whitening: List[int]) -> int:\n",
    "    return HW[(k + whitening[round_idx * BLOCK_WIDTH_B4 + block_idx]) % 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_all = np.tile(np.arange(traces[0].shape[1]), (KEYROUND_WIDTH_B4 // BLOCK_WIDTH_B4, BLOCK_WIDTH_B4, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key 0: \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.98 PiB for an array with shape (512, 2, 16, 255998, 100000) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m hypotheses \u001b[38;5;241m=\u001b[39m multiple_locations_and_hypotheses(hypotheses_funs, seeds[i])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#corrs = np.array([[corr_coef_vectorized(hypotheses[l], selected_traces) for l in range(hypotheses.shape[0])] for selected_traces, hypotheses in zip(list_selected_traces, list_hypotheses)])\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m corrs \u001b[38;5;241m=\u001b[39m \u001b[43mcorr_coef_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypotheses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# fig, axs = plt.subplots(corrs.shape[0], 2, figsize=(16, 20))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# if corrs.shape[0] == 1:\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     axs = axs[np.newaxis, :]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#     axs[k, 0].set_ylim([-0.5, 0.5])\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#     axs[k, 0].set_title(hypotheses_names[k])\u001b[39;00m\n\u001b[0;32m     20\u001b[0m max_corrs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(corrs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Kudelski\\Documents\\Pierugo-PDM-2024\\side_channel_attack\\cpa_utils.py:57\u001b[0m, in \u001b[0;36mcorr_coef_vectorized\u001b[1;34m(hypotheses, traces)\u001b[0m\n\u001b[0;32m     54\u001b[0m t_mean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(traces, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# np.mean(traces, axis=0)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m h_diff, t_diff \u001b[38;5;241m=\u001b[39m hypotheses \u001b[38;5;241m-\u001b[39m h_mean[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis], traces \u001b[38;5;241m-\u001b[39m t_mean\n\u001b[1;32m---> 57\u001b[0m r_num \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mh_diff\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt_diff\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# np.sum(h_diff[:, None] * t_diff, axis=0)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m r_den \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39msum(h_diff \u001b[38;5;241m*\u001b[39m h_diff, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39msum(t_diff \u001b[38;5;241m*\u001b[39m t_diff, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)) \u001b[38;5;66;03m# np.sqrt(np.sum(h_diff * h_diff, axis=0) * np.sum(t_diff * t_diff, axis=0))\u001b[39;00m\n\u001b[0;32m     59\u001b[0m r \u001b[38;5;241m=\u001b[39m r_num \u001b[38;5;241m/\u001b[39m r_den\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.98 PiB for an array with shape (512, 2, 16, 255998, 100000) and data type float64"
     ]
    }
   ],
   "source": [
    "hypotheses_funs = [hyp_even_sbox_output, hyp_hw_x_i]\n",
    "\n",
    "reconstructed_keys = np.zeros_like(real_keys)\n",
    "for i in range(reconstructed_keys.shape[0]):\n",
    "    print(f\"Key {i}: \")\n",
    "    hypotheses = multiple_locations_and_hypotheses(hypotheses_funs, seeds[i])\n",
    "    #corrs = np.array([[corr_coef_vectorized(hypotheses[l], selected_traces) for l in range(hypotheses.shape[0])] for selected_traces, hypotheses in zip(list_selected_traces, list_hypotheses)])\n",
    "    corrs = corr_coef_vectorized(hypotheses, traces[i])\n",
    "\n",
    "    # fig, axs = plt.subplots(corrs.shape[0], 2, figsize=(16, 20))\n",
    "    # if corrs.shape[0] == 1:\n",
    "    #     axs = axs[np.newaxis, :]\n",
    "    # for k in range(corrs.shape[0]):\n",
    "    #     for l in range(corrs.shape[1]):\n",
    "    #         axs[k, 0].plot(corrs[k][l], label=str(l))\n",
    "\n",
    "    #     axs[k, 0].set_ylim([-0.5, 0.5])\n",
    "    #     axs[k, 0].set_title(hypotheses_names[k])\n",
    "        \n",
    "    max_corrs = np.max(corrs, axis=2)\n",
    "    best_k_per_hyp = np.argmax(max_corrs, axis=1)\n",
    "    if True:\n",
    "        mean_corrs = np.mean(max_corrs, axis=0)\n",
    "        best_k = np.argmax(mean_corrs) # Correlation mean\n",
    "    else:\n",
    "        best_k = Counter(best_k_per_hyp).most_common(1)[0][0] # Majority voting\n",
    "    reconstructed_keys[i][j] = best_k\n",
    "\n",
    "    # for k in range(max_corrs.shape[0]):\n",
    "    #     axs[k, 1].plot(max_corrs[k])\n",
    "    #     axs[k, 1].set_xlabel(\"Key\")\n",
    "    #     axs[k, 1].set_ylabel(\"Max correlation\")\n",
    "    #     axs[k, 1].set_title(f\"Real key nibble: {real_keys[i][j]}, chosen {best_k_per_hyp[k]}\")\n",
    "    #     axs[k, 1].set_ylim([0, 0.5])\n",
    "    # plt.show()\n",
    "    print(f\"Chosen {best_k}\")\n",
    "\n",
    "    print()\n",
    "    print(f\"    vs {\"\".join([hex(k)[2:].upper() for k in real_keys[i]])}\")\n",
    "    print(f\"{len(real_keys[i][real_keys[i] != reconstructed_keys[i]])} mistakes on {len(real_keys[i])} nibbles.\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
