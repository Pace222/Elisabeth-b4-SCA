{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pickle as pic\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-12 09:16:51.843797: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-12 09:16:51.893151: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-12 09:16:52.834310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import deep_learning"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["if True:\n","    with open(\"splitted_round_4.pic\", \"rb\") as r:\n","        X_training, X_val, X_extraction = pic.load(r)\n","    with open(\"splitted_labels_1000000.pic\", \"rb\") as r:\n","        y_training, y_val, y_extraction = pic.load(r)\n","else:\n","    with open(\"traces_round_4_adjusted_only.pic\", \"rb\") as r:\n","        traces_round_4 = pic.load(r)\n","    with open(\"labels_1000000.pic\", \"rb\") as r:\n","        rws_perms_labels, round_perms_labels, copy_perms_labels, rws_masks_labels, round_masks_labels = pic.load(r)\n","\n","    X_total, y_total = deep_learning.prepare_data_dl(traces_round_4, round_perms_labels, copy_perms_labels, round_masks_labels, rws_perms_labels, rws_masks_labels)\n","\n","    profile, test = train_test_split(np.arange(X_total.shape[0]), train_size=750_000, random_state=0)\n","\n","    X_profiling, X_extraction = X_total[profile], X_total[test]\n","    train, val = train_test_split(np.arange(X_profiling.shape[0]), test_size=0.1, random_state=0)\n","    X_training, X_val = X_profiling[train], X_profiling[val]\n","\n","    with open(\"splitted_round_4.pic\", \"wb\") as w:\n","        pic.dump((X_training, X_val, X_extraction), w)\n","\n","    if False:\n","        y_profiling = {}\n","        y_training = {}\n","        y_val = {}\n","        y_extraction = {}\n","        for label in y_total.keys():\n","            print(label, end=\"\\r\")\n","            y_profiling[label], y_extraction[label] = y_total[label][profile], y_total[label][test]\n","            y_training[label], y_val[label] = y_profiling[label][train], y_profiling[label][val]\n","\n","        with open(\"splitted_labels_1000000.pic\", \"wb\") as w:\n","            pic.dump((y_training, y_val, y_extraction), w)\n","    else:\n","        with open(\"splitted_labels_1000000.pic\", \"rb\") as r:\n","            y_training, y_val, y_extraction = pic.load(r)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-12 09:16:55.855126: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:55.893995: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:55.894063: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:55.906962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:55.907060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:55.907097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:56.100368: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:56.100482: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:56.100492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2024-06-12 09:16:56.100533: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:1a:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-12 09:16:56.100563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n"]}],"source":["resnet = deep_learning.ResNetSCA(network=\"orig_round_4\", epochs=1000, dataset_size=X_training.shape[0])\n","try:\n","    deep_learning.check_file_exists(\"./resnet_models/resnet_750000_orig_round_4_adjusted.keras\")\n","    from tensorflow.keras.models import load_model\n","    resnet.model = load_model(\"./resnet_models/resnet_750000_orig_round_4_adjusted.keras\")\n","except ValueError:\n","    pass"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["train_gen = deep_learning.DataGenerator(X_training, y_training)\n","val_gen = deep_learning.DataGenerator(X_val, y_val)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-12 09:17:17.477831: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n","/root/Pierugo/protected_side_channel_attack/.venv_linux/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1718176637.687996   48896 service.cc:145] XLA service 0x7f3530076310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1718176637.688051   48896 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 Ti, Compute Capability 7.5\n","2024-06-12 09:17:18.282041: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-06-12 09:17:20.764677: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n","2024-06-12 09:17:24.346401: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 12.11GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1718176654.789829   48896 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_40', 120 bytes spill stores, 120 bytes spill loads\n","\n","I0000 00:00:1718176654.824359   48896 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6599/10547\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m4:03\u001b[0m 62ms/step - block_perm_4_output_accuracy: 0.1438 - loss: 41.4195 - mask_4_0_0_output_accuracy: 0.0624 - mask_4_0_1_output_accuracy: 0.0630 - mask_4_1_0_output_accuracy: 0.0622 - mask_4_1_1_output_accuracy: 0.0619 - mask_4_2_0_output_accuracy: 0.0624 - mask_4_2_1_output_accuracy: 0.0619 - mask_4_3_0_output_accuracy: 0.0629 - mask_4_3_1_output_accuracy: 0.0629 - mask_4_4_0_output_accuracy: 0.0623 - mask_4_4_1_output_accuracy: 0.0629 - mask_4_5_0_output_accuracy: 0.0621 - mask_4_5_1_output_accuracy: 0.0620 - mask_4_6_0_output_accuracy: 0.0626 - mask_4_6_1_output_accuracy: 0.0622"]},{"name":"stderr","output_type":"stream","text":["2024-06-12 09:24:28.231435: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 11.61GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n","I0000 00:00:1718177080.588444   48896 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_41', 120 bytes spill stores, 120 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m735s\u001b[0m 66ms/step - block_perm_4_output_accuracy: 0.1437 - loss: 41.3849 - mask_4_0_0_output_accuracy: 0.0625 - mask_4_0_1_output_accuracy: 0.0627 - mask_4_1_0_output_accuracy: 0.0622 - mask_4_1_1_output_accuracy: 0.0621 - mask_4_2_0_output_accuracy: 0.0624 - mask_4_2_1_output_accuracy: 0.0620 - mask_4_3_0_output_accuracy: 0.0627 - mask_4_3_1_output_accuracy: 0.0631 - mask_4_4_0_output_accuracy: 0.0624 - mask_4_4_1_output_accuracy: 0.0629 - mask_4_5_0_output_accuracy: 0.0622 - mask_4_5_1_output_accuracy: 0.0621 - mask_4_6_0_output_accuracy: 0.0625 - mask_4_6_1_output_accuracy: 0.0625 - val_block_perm_4_output_accuracy: 0.1408 - val_loss: 58.2287 - val_mask_4_0_0_output_accuracy: 0.0615 - val_mask_4_0_1_output_accuracy: 0.0619 - val_mask_4_1_0_output_accuracy: 0.0649 - val_mask_4_1_1_output_accuracy: 0.0624 - val_mask_4_2_0_output_accuracy: 0.0610 - val_mask_4_2_1_output_accuracy: 0.0621 - val_mask_4_3_0_output_accuracy: 0.0622 - val_mask_4_3_1_output_accuracy: 0.0628 - val_mask_4_4_0_output_accuracy: 0.0617 - val_mask_4_4_1_output_accuracy: 0.0623 - val_mask_4_5_0_output_accuracy: 0.0634 - val_mask_4_5_1_output_accuracy: 0.0634 - val_mask_4_6_0_output_accuracy: 0.0624 - val_mask_4_6_1_output_accuracy: 0.0625\n","Epoch 2/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m666s\u001b[0m 63ms/step - block_perm_4_output_accuracy: 0.1458 - loss: 41.1252 - mask_4_0_0_output_accuracy: 0.0627 - mask_4_0_1_output_accuracy: 0.0632 - mask_4_1_0_output_accuracy: 0.0625 - mask_4_1_1_output_accuracy: 0.0622 - mask_4_2_0_output_accuracy: 0.0616 - mask_4_2_1_output_accuracy: 0.0619 - mask_4_3_0_output_accuracy: 0.0630 - mask_4_3_1_output_accuracy: 0.0621 - mask_4_4_0_output_accuracy: 0.0630 - mask_4_4_1_output_accuracy: 0.0626 - mask_4_5_0_output_accuracy: 0.0622 - mask_4_5_1_output_accuracy: 0.0623 - mask_4_6_0_output_accuracy: 0.0628 - mask_4_6_1_output_accuracy: 0.0624 - val_block_perm_4_output_accuracy: 0.1453 - val_loss: 46.0700 - val_mask_4_0_0_output_accuracy: 0.0629 - val_mask_4_0_1_output_accuracy: 0.0624 - val_mask_4_1_0_output_accuracy: 0.0620 - val_mask_4_1_1_output_accuracy: 0.0619 - val_mask_4_2_0_output_accuracy: 0.0635 - val_mask_4_2_1_output_accuracy: 0.0633 - val_mask_4_3_0_output_accuracy: 0.0613 - val_mask_4_3_1_output_accuracy: 0.0617 - val_mask_4_4_0_output_accuracy: 0.0612 - val_mask_4_4_1_output_accuracy: 0.0633 - val_mask_4_5_0_output_accuracy: 0.0635 - val_mask_4_5_1_output_accuracy: 0.0615 - val_mask_4_6_0_output_accuracy: 0.0632 - val_mask_4_6_1_output_accuracy: 0.0623\n","Epoch 3/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m684s\u001b[0m 65ms/step - block_perm_4_output_accuracy: 0.4488 - loss: 40.3007 - mask_4_0_0_output_accuracy: 0.0686 - mask_4_0_1_output_accuracy: 0.0704 - mask_4_1_0_output_accuracy: 0.0683 - mask_4_1_1_output_accuracy: 0.0697 - mask_4_2_0_output_accuracy: 0.0675 - mask_4_2_1_output_accuracy: 0.0684 - mask_4_3_0_output_accuracy: 0.0675 - mask_4_3_1_output_accuracy: 0.0706 - mask_4_4_0_output_accuracy: 0.0677 - mask_4_4_1_output_accuracy: 0.0698 - mask_4_5_0_output_accuracy: 0.0689 - mask_4_5_1_output_accuracy: 0.0697 - mask_4_6_0_output_accuracy: 0.0682 - mask_4_6_1_output_accuracy: 0.0683 - val_block_perm_4_output_accuracy: 0.3957 - val_loss: 41.1457 - val_mask_4_0_0_output_accuracy: 0.0742 - val_mask_4_0_1_output_accuracy: 0.0830 - val_mask_4_1_0_output_accuracy: 0.0644 - val_mask_4_1_1_output_accuracy: 0.0667 - val_mask_4_2_0_output_accuracy: 0.0664 - val_mask_4_2_1_output_accuracy: 0.0730 - val_mask_4_3_0_output_accuracy: 0.0815 - val_mask_4_3_1_output_accuracy: 0.0779 - val_mask_4_4_0_output_accuracy: 0.0799 - val_mask_4_4_1_output_accuracy: 0.0749 - val_mask_4_5_0_output_accuracy: 0.0826 - val_mask_4_5_1_output_accuracy: 0.0788 - val_mask_4_6_0_output_accuracy: 0.0639 - val_mask_4_6_1_output_accuracy: 0.0765\n","Epoch 4/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m669s\u001b[0m 63ms/step - block_perm_4_output_accuracy: 0.6496 - loss: 39.5305 - mask_4_0_0_output_accuracy: 0.0871 - mask_4_0_1_output_accuracy: 0.0891 - mask_4_1_0_output_accuracy: 0.0848 - mask_4_1_1_output_accuracy: 0.0874 - mask_4_2_0_output_accuracy: 0.0839 - mask_4_2_1_output_accuracy: 0.0868 - mask_4_3_0_output_accuracy: 0.0839 - mask_4_3_1_output_accuracy: 0.0882 - mask_4_4_0_output_accuracy: 0.0849 - mask_4_4_1_output_accuracy: 0.0870 - mask_4_5_0_output_accuracy: 0.0861 - mask_4_5_1_output_accuracy: 0.0879 - mask_4_6_0_output_accuracy: 0.0876 - mask_4_6_1_output_accuracy: 0.0871 - val_block_perm_4_output_accuracy: 0.3570 - val_loss: 44.4923 - val_mask_4_0_0_output_accuracy: 0.0640 - val_mask_4_0_1_output_accuracy: 0.0625 - val_mask_4_1_0_output_accuracy: 0.0716 - val_mask_4_1_1_output_accuracy: 0.0829 - val_mask_4_2_0_output_accuracy: 0.0799 - val_mask_4_2_1_output_accuracy: 0.0730 - val_mask_4_3_0_output_accuracy: 0.0715 - val_mask_4_3_1_output_accuracy: 0.0769 - val_mask_4_4_0_output_accuracy: 0.0623 - val_mask_4_4_1_output_accuracy: 0.0686 - val_mask_4_5_0_output_accuracy: 0.0627 - val_mask_4_5_1_output_accuracy: 0.0628 - val_mask_4_6_0_output_accuracy: 0.0624 - val_mask_4_6_1_output_accuracy: 0.0712\n","Epoch 5/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m675s\u001b[0m 64ms/step - block_perm_4_output_accuracy: 0.6678 - loss: 39.4398 - mask_4_0_0_output_accuracy: 0.0883 - mask_4_0_1_output_accuracy: 0.0921 - mask_4_1_0_output_accuracy: 0.0865 - mask_4_1_1_output_accuracy: 0.0900 - mask_4_2_0_output_accuracy: 0.0855 - mask_4_2_1_output_accuracy: 0.0898 - mask_4_3_0_output_accuracy: 0.0858 - mask_4_3_1_output_accuracy: 0.0898 - mask_4_4_0_output_accuracy: 0.0870 - mask_4_4_1_output_accuracy: 0.0895 - mask_4_5_0_output_accuracy: 0.0875 - mask_4_5_1_output_accuracy: 0.0903 - mask_4_6_0_output_accuracy: 0.0891 - mask_4_6_1_output_accuracy: 0.0894 - val_block_perm_4_output_accuracy: 0.4476 - val_loss: 40.7049 - val_mask_4_0_0_output_accuracy: 0.0862 - val_mask_4_0_1_output_accuracy: 0.0873 - val_mask_4_1_0_output_accuracy: 0.0678 - val_mask_4_1_1_output_accuracy: 0.0839 - val_mask_4_2_0_output_accuracy: 0.0823 - val_mask_4_2_1_output_accuracy: 0.0781 - val_mask_4_3_0_output_accuracy: 0.0620 - val_mask_4_3_1_output_accuracy: 0.0793 - val_mask_4_4_0_output_accuracy: 0.0712 - val_mask_4_4_1_output_accuracy: 0.0873 - val_mask_4_5_0_output_accuracy: 0.0815 - val_mask_4_5_1_output_accuracy: 0.0819 - val_mask_4_6_0_output_accuracy: 0.0694 - val_mask_4_6_1_output_accuracy: 0.0769\n","Epoch 6/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 63ms/step - block_perm_4_output_accuracy: 0.6785 - loss: 39.3877 - mask_4_0_0_output_accuracy: 0.0904 - mask_4_0_1_output_accuracy: 0.0938 - mask_4_1_0_output_accuracy: 0.0864 - mask_4_1_1_output_accuracy: 0.0910 - mask_4_2_0_output_accuracy: 0.0861 - mask_4_2_1_output_accuracy: 0.0891 - mask_4_3_0_output_accuracy: 0.0866 - mask_4_3_1_output_accuracy: 0.0903 - mask_4_4_0_output_accuracy: 0.0881 - mask_4_4_1_output_accuracy: 0.0901 - mask_4_5_0_output_accuracy: 0.0883 - mask_4_5_1_output_accuracy: 0.0916 - mask_4_6_0_output_accuracy: 0.0895 - mask_4_6_1_output_accuracy: 0.0895 - val_block_perm_4_output_accuracy: 0.3463 - val_loss: 40.8065 - val_mask_4_0_0_output_accuracy: 0.0869 - val_mask_4_0_1_output_accuracy: 0.0906 - val_mask_4_1_0_output_accuracy: 0.0859 - val_mask_4_1_1_output_accuracy: 0.0900 - val_mask_4_2_0_output_accuracy: 0.0803 - val_mask_4_2_1_output_accuracy: 0.0769 - val_mask_4_3_0_output_accuracy: 0.0836 - val_mask_4_3_1_output_accuracy: 0.0811 - val_mask_4_4_0_output_accuracy: 0.0786 - val_mask_4_4_1_output_accuracy: 0.0836 - val_mask_4_5_0_output_accuracy: 0.0871 - val_mask_4_5_1_output_accuracy: 0.0855 - val_mask_4_6_0_output_accuracy: 0.0833 - val_mask_4_6_1_output_accuracy: 0.0876\n","Epoch 7/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m679s\u001b[0m 64ms/step - block_perm_4_output_accuracy: 0.6841 - loss: 39.3595 - mask_4_0_0_output_accuracy: 0.0917 - mask_4_0_1_output_accuracy: 0.0935 - mask_4_1_0_output_accuracy: 0.0866 - mask_4_1_1_output_accuracy: 0.0922 - mask_4_2_0_output_accuracy: 0.0869 - mask_4_2_1_output_accuracy: 0.0899 - mask_4_3_0_output_accuracy: 0.0869 - mask_4_3_1_output_accuracy: 0.0908 - mask_4_4_0_output_accuracy: 0.0883 - mask_4_4_1_output_accuracy: 0.0903 - mask_4_5_0_output_accuracy: 0.0881 - mask_4_5_1_output_accuracy: 0.0919 - mask_4_6_0_output_accuracy: 0.0901 - mask_4_6_1_output_accuracy: 0.0896 - val_block_perm_4_output_accuracy: 0.5423 - val_loss: 40.2384 - val_mask_4_0_0_output_accuracy: 0.0724 - val_mask_4_0_1_output_accuracy: 0.0877 - val_mask_4_1_0_output_accuracy: 0.0860 - val_mask_4_1_1_output_accuracy: 0.0915 - val_mask_4_2_0_output_accuracy: 0.0810 - val_mask_4_2_1_output_accuracy: 0.0849 - val_mask_4_3_0_output_accuracy: 0.0823 - val_mask_4_3_1_output_accuracy: 0.0842 - val_mask_4_4_0_output_accuracy: 0.0866 - val_mask_4_4_1_output_accuracy: 0.0848 - val_mask_4_5_0_output_accuracy: 0.0652 - val_mask_4_5_1_output_accuracy: 0.0756 - val_mask_4_6_0_output_accuracy: 0.0841 - val_mask_4_6_1_output_accuracy: 0.0863\n","Epoch 8/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 64ms/step - block_perm_4_output_accuracy: 0.6882 - loss: 39.3308 - mask_4_0_0_output_accuracy: 0.0917 - mask_4_0_1_output_accuracy: 0.0954 - mask_4_1_0_output_accuracy: 0.0874 - mask_4_1_1_output_accuracy: 0.0921 - mask_4_2_0_output_accuracy: 0.0869 - mask_4_2_1_output_accuracy: 0.0908 - mask_4_3_0_output_accuracy: 0.0876 - mask_4_3_1_output_accuracy: 0.0920 - mask_4_4_0_output_accuracy: 0.0885 - mask_4_4_1_output_accuracy: 0.0925 - mask_4_5_0_output_accuracy: 0.0886 - mask_4_5_1_output_accuracy: 0.0934 - mask_4_6_0_output_accuracy: 0.0906 - mask_4_6_1_output_accuracy: 0.0902 - val_block_perm_4_output_accuracy: 0.5194 - val_loss: 41.2025 - val_mask_4_0_0_output_accuracy: 0.0783 - val_mask_4_0_1_output_accuracy: 0.0845 - val_mask_4_1_0_output_accuracy: 0.0634 - val_mask_4_1_1_output_accuracy: 0.0672 - val_mask_4_2_0_output_accuracy: 0.0688 - val_mask_4_2_1_output_accuracy: 0.0711 - val_mask_4_3_0_output_accuracy: 0.0823 - val_mask_4_3_1_output_accuracy: 0.0730 - val_mask_4_4_0_output_accuracy: 0.0743 - val_mask_4_4_1_output_accuracy: 0.0859 - val_mask_4_5_0_output_accuracy: 0.0658 - val_mask_4_5_1_output_accuracy: 0.0664 - val_mask_4_6_0_output_accuracy: 0.0800 - val_mask_4_6_1_output_accuracy: 0.0859\n","Epoch 9/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m668s\u001b[0m 63ms/step - block_perm_4_output_accuracy: 0.6926 - loss: 39.3086 - mask_4_0_0_output_accuracy: 0.0921 - mask_4_0_1_output_accuracy: 0.0950 - mask_4_1_0_output_accuracy: 0.0881 - mask_4_1_1_output_accuracy: 0.0925 - mask_4_2_0_output_accuracy: 0.0877 - mask_4_2_1_output_accuracy: 0.0908 - mask_4_3_0_output_accuracy: 0.0883 - mask_4_3_1_output_accuracy: 0.0923 - mask_4_4_0_output_accuracy: 0.0888 - mask_4_4_1_output_accuracy: 0.0918 - mask_4_5_0_output_accuracy: 0.0892 - mask_4_5_1_output_accuracy: 0.0931 - mask_4_6_0_output_accuracy: 0.0907 - mask_4_6_1_output_accuracy: 0.0913 - val_block_perm_4_output_accuracy: 0.5544 - val_loss: 40.3514 - val_mask_4_0_0_output_accuracy: 0.0755 - val_mask_4_0_1_output_accuracy: 0.0688 - val_mask_4_1_0_output_accuracy: 0.0842 - val_mask_4_1_1_output_accuracy: 0.0803 - val_mask_4_2_0_output_accuracy: 0.0830 - val_mask_4_2_1_output_accuracy: 0.0754 - val_mask_4_3_0_output_accuracy: 0.0824 - val_mask_4_3_1_output_accuracy: 0.0857 - val_mask_4_4_0_output_accuracy: 0.0853 - val_mask_4_4_1_output_accuracy: 0.0837 - val_mask_4_5_0_output_accuracy: 0.0786 - val_mask_4_5_1_output_accuracy: 0.0809 - val_mask_4_6_0_output_accuracy: 0.0830 - val_mask_4_6_1_output_accuracy: 0.0783\n","Epoch 10/1000\n","\u001b[1m10392/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m9s\u001b[0m 62ms/step - block_perm_4_output_accuracy: 0.6950 - loss: 39.2961 - mask_4_0_0_output_accuracy: 0.0922 - mask_4_0_1_output_accuracy: 0.0965 - mask_4_1_0_output_accuracy: 0.0887 - mask_4_1_1_output_accuracy: 0.0924 - mask_4_2_0_output_accuracy: 0.0886 - mask_4_2_1_output_accuracy: 0.0920 - mask_4_3_0_output_accuracy: 0.0881 - mask_4_3_1_output_accuracy: 0.0927 - mask_4_4_0_output_accuracy: 0.0895 - mask_4_4_1_output_accuracy: 0.0923 - mask_4_5_0_output_accuracy: 0.0895 - mask_4_5_1_output_accuracy: 0.0942 - mask_4_6_0_output_accuracy: 0.0916 - mask_4_6_1_output_accuracy: 0.0910"]}],"source":["history = resnet.train_model_generator(train_gen, val_gen, \"./resnet_models/resnet_750000_orig_round_4_adjusted.keras\", patience=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
