{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n","os.environ['CUDA_VISIBLE_DEVICES'] = \"6\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pickle as pic\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-17 14:57:13.957743: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2024-06-17 14:57:14.014816: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-06-17 14:57:14.974594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import deep_learning"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["if True:\n","    with open(\"splitted_rws.pic\", \"rb\") as r:\n","        X_training, X_val, X_extraction = pic.load(r)\n","        X_training, X_val, X_extraction = X_training[:, 9930:14790], X_val[:, 9930:14790], X_extraction[:, 9930:14790]\n","    with open(\"splitted_labels_1000000.pic\", \"rb\") as r:\n","        y_training, y_val, y_extraction = pic.load(r)\n","else:\n","    with open(\"traces_rws_only.pic\", \"rb\") as r:\n","        traces_rws_only = pic.load(r)\n","    with open(\"labels_1000000.pic\", \"rb\") as r:\n","        rws_perms_labels, round_perms_labels, copy_perms_labels, rws_masks_labels, round_masks_labels = pic.load(r)\n","\n","    X_total, y_total = deep_learning.prepare_data_dl(traces_rws_only, round_perms_labels, copy_perms_labels, round_masks_labels, rws_perms_labels, rws_masks_labels)\n","\n","    profile, test = train_test_split(np.arange(X_total.shape[0]), train_size=750_000, random_state=0)\n","\n","    X_profiling, X_extraction = X_total[profile], X_total[test]\n","    train, val = train_test_split(np.arange(X_profiling.shape[0]), test_size=0.1, random_state=0)\n","    X_training, X_val = X_profiling[train], X_profiling[val]\n","\n","    with open(\"splitted_rws.pic\", \"wb\") as w:\n","        pic.dump((X_training, X_val, X_extraction), w)\n","\n","    if False:\n","        y_profiling = {}\n","        y_training = {}\n","        y_val = {}\n","        y_extraction = {}\n","        for label in y_total.keys():\n","            print(label, end=\"\\r\")\n","            y_profiling[label], y_extraction[label] = y_total[label][profile], y_total[label][test]\n","            y_training[label], y_val[label] = y_profiling[label][train], y_profiling[label][val]\n","\n","        with open(\"splitted_labels_1000000.pic\", \"wb\") as w:\n","            pic.dump((y_training, y_val, y_extraction), w)\n","    else:\n","        with open(\"splitted_labels_1000000.pic\", \"rb\") as r:\n","            y_training, y_val, y_extraction = pic.load(r)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-17 14:57:36.375625: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.416463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.416518: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.429495: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.429570: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.429602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.644875: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.644944: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.644955: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2024-06-17 14:57:36.645000: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:da:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2024-06-17 14:57:36.645031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21742 MB memory:  -> device: 0, name: NVIDIA RTX 4500 Ada Generation, pci bus id: 0000:da:00.0, compute capability: 8.9\n"]}],"source":["resnet = deep_learning.ResNetSCA(network=\"orig_rws_2\", epochs=1000, dataset_size=X_training.shape[0])\n","try:\n","    deep_learning.check_file_exists(\"./resnet_models/resnet_750000_orig_rws_2.keras\")\n","    from tensorflow.keras.models import load_model\n","    resnet.model = load_model(\"./resnet_models/resnet_750000_orig_rws_2.keras\")\n","except ValueError:\n","    pass"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["X_training = np.pad(X_training, ((0, 0), (resnet.model.input.shape[1] - X_training.shape[1], 0)))\n","X_val = np.pad(X_val, ((0, 0), (resnet.model.input.shape[1] - X_val.shape[1], 0)))"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["train_gen = deep_learning.DataGenerator(X_training, y_training)\n","val_gen = deep_learning.DataGenerator(X_val, y_val)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["new_y_train = {}\n","new_y_val = {}\n","for output in train_gen.y.keys():\n","    idx = int(output[len('rws_mask_'):][:2])\n","    shx = int(output[len('rws_mask_XX_')])\n","    new_y_train[f'rws_mask_{idx - 48}_{shx}_output'] = train_gen.y[output]\n","    new_y_val[f'rws_mask_{idx - 48}_{shx}_output'] = val_gen.y[output]\n","train_gen.y = new_y_train\n","val_gen.y = new_y_val"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n"]},{"name":"stderr","output_type":"stream","text":["2024-06-17 15:00:10.155579: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n","/root/Pierugo/protected_side_channel_attack/.venv_linux/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1718629210.642022   59829 service.cc:145] XLA service 0x7f452411f100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1718629210.642074   59829 service.cc:153]   StreamExecutor device (0): NVIDIA RTX 4500 Ada Generation, Compute Capability 8.9\n","2024-06-17 15:00:12.359172: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-06-17 15:00:17.919647: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1718629255.633308   59829 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_62', 72 bytes spill stores, 72 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_61', 72 bytes spill stores, 72 bytes spill loads\n","\n","I0000 00:00:1718629255.719744   59829 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 6851/10547\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m6:38\u001b[0m 108ms/step - loss: 130.3701 - rws_mask_0_0_output_accuracy: 0.1070 - rws_mask_0_1_output_accuracy: 0.0917 - rws_mask_10_0_output_accuracy: 0.1078 - rws_mask_10_1_output_accuracy: 0.0911 - rws_mask_11_0_output_accuracy: 0.1077 - rws_mask_11_1_output_accuracy: 0.0914 - rws_mask_12_0_output_accuracy: 0.1051 - rws_mask_12_1_output_accuracy: 0.0927 - rws_mask_13_0_output_accuracy: 0.1082 - rws_mask_13_1_output_accuracy: 0.0926 - rws_mask_14_0_output_accuracy: 0.1064 - rws_mask_14_1_output_accuracy: 0.0916 - rws_mask_15_0_output_accuracy: 0.1066 - rws_mask_15_1_output_accuracy: 0.0920 - rws_mask_16_0_output_accuracy: 0.1087 - rws_mask_16_1_output_accuracy: 0.0913 - rws_mask_17_0_output_accuracy: 0.1076 - rws_mask_17_1_output_accuracy: 0.0916 - rws_mask_18_0_output_accuracy: 0.1079 - rws_mask_18_1_output_accuracy: 0.0923 - rws_mask_19_0_output_accuracy: 0.1078 - rws_mask_19_1_output_accuracy: 0.0919 - rws_mask_1_0_output_accuracy: 0.1086 - rws_mask_1_1_output_accuracy: 0.0906 - rws_mask_20_0_output_accuracy: 0.1056 - rws_mask_20_1_output_accuracy: 0.0910 - rws_mask_21_0_output_accuracy: 0.1085 - rws_mask_21_1_output_accuracy: 0.0926 - rws_mask_22_0_output_accuracy: 0.1072 - rws_mask_22_1_output_accuracy: 0.0928 - rws_mask_23_0_output_accuracy: 0.1042 - rws_mask_23_1_output_accuracy: 0.0872 - rws_mask_2_0_output_accuracy: 0.1065 - rws_mask_2_1_output_accuracy: 0.0913 - rws_mask_3_0_output_accuracy: 0.1080 - rws_mask_3_1_output_accuracy: 0.0905 - rws_mask_4_0_output_accuracy: 0.1066 - rws_mask_4_1_output_accuracy: 0.0925 - rws_mask_5_0_output_accuracy: 0.1068 - rws_mask_5_1_output_accuracy: 0.0925 - rws_mask_6_0_output_accuracy: 0.1076 - rws_mask_6_1_output_accuracy: 0.0908 - rws_mask_7_0_output_accuracy: 0.1061 - rws_mask_7_1_output_accuracy: 0.0927 - rws_mask_8_0_output_accuracy: 0.1077 - rws_mask_8_1_output_accuracy: 0.0926 - rws_mask_9_0_output_accuracy: 0.1066 - rws_mask_9_1_output_accuracy: 0.0919"]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1718630033.652427   59835 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_69', 72 bytes spill stores, 72 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1302s\u001b[0m 116ms/step - loss: 130.3694 - rws_mask_0_0_output_accuracy: 0.1071 - rws_mask_0_1_output_accuracy: 0.0916 - rws_mask_10_0_output_accuracy: 0.1077 - rws_mask_10_1_output_accuracy: 0.0914 - rws_mask_11_0_output_accuracy: 0.1078 - rws_mask_11_1_output_accuracy: 0.0915 - rws_mask_12_0_output_accuracy: 0.1055 - rws_mask_12_1_output_accuracy: 0.0925 - rws_mask_13_0_output_accuracy: 0.1082 - rws_mask_13_1_output_accuracy: 0.0923 - rws_mask_14_0_output_accuracy: 0.1064 - rws_mask_14_1_output_accuracy: 0.0915 - rws_mask_15_0_output_accuracy: 0.1065 - rws_mask_15_1_output_accuracy: 0.0920 - rws_mask_16_0_output_accuracy: 0.1086 - rws_mask_16_1_output_accuracy: 0.0914 - rws_mask_17_0_output_accuracy: 0.1074 - rws_mask_17_1_output_accuracy: 0.0917 - rws_mask_18_0_output_accuracy: 0.1077 - rws_mask_18_1_output_accuracy: 0.0923 - rws_mask_19_0_output_accuracy: 0.1076 - rws_mask_19_1_output_accuracy: 0.0919 - rws_mask_1_0_output_accuracy: 0.1083 - rws_mask_1_1_output_accuracy: 0.0906 - rws_mask_20_0_output_accuracy: 0.1058 - rws_mask_20_1_output_accuracy: 0.0911 - rws_mask_21_0_output_accuracy: 0.1084 - rws_mask_21_1_output_accuracy: 0.0925 - rws_mask_22_0_output_accuracy: 0.1071 - rws_mask_22_1_output_accuracy: 0.0927 - rws_mask_23_0_output_accuracy: 0.1043 - rws_mask_23_1_output_accuracy: 0.0872 - rws_mask_2_0_output_accuracy: 0.1064 - rws_mask_2_1_output_accuracy: 0.0915 - rws_mask_3_0_output_accuracy: 0.1082 - rws_mask_3_1_output_accuracy: 0.0909 - rws_mask_4_0_output_accuracy: 0.1066 - rws_mask_4_1_output_accuracy: 0.0921 - rws_mask_5_0_output_accuracy: 0.1068 - rws_mask_5_1_output_accuracy: 0.0924 - rws_mask_6_0_output_accuracy: 0.1075 - rws_mask_6_1_output_accuracy: 0.0908 - rws_mask_7_0_output_accuracy: 0.1062 - rws_mask_7_1_output_accuracy: 0.0925 - rws_mask_8_0_output_accuracy: 0.1076 - rws_mask_8_1_output_accuracy: 0.0922 - rws_mask_9_0_output_accuracy: 0.1065 - rws_mask_9_1_output_accuracy: 0.0919 - val_loss: 131.5070 - val_rws_mask_0_0_output_accuracy: 0.0944 - val_rws_mask_0_1_output_accuracy: 0.0907 - val_rws_mask_10_0_output_accuracy: 0.1039 - val_rws_mask_10_1_output_accuracy: 0.0912 - val_rws_mask_11_0_output_accuracy: 0.1051 - val_rws_mask_11_1_output_accuracy: 0.0904 - val_rws_mask_12_0_output_accuracy: 0.1063 - val_rws_mask_12_1_output_accuracy: 0.0908 - val_rws_mask_13_0_output_accuracy: 0.0981 - val_rws_mask_13_1_output_accuracy: 0.0883 - val_rws_mask_14_0_output_accuracy: 0.1006 - val_rws_mask_14_1_output_accuracy: 0.0903 - val_rws_mask_15_0_output_accuracy: 0.1077 - val_rws_mask_15_1_output_accuracy: 0.0897 - val_rws_mask_16_0_output_accuracy: 0.1060 - val_rws_mask_16_1_output_accuracy: 0.0849 - val_rws_mask_17_0_output_accuracy: 0.0927 - val_rws_mask_17_1_output_accuracy: 0.0873 - val_rws_mask_18_0_output_accuracy: 0.0891 - val_rws_mask_18_1_output_accuracy: 0.0897 - val_rws_mask_19_0_output_accuracy: 0.0995 - val_rws_mask_19_1_output_accuracy: 0.0852 - val_rws_mask_1_0_output_accuracy: 0.0836 - val_rws_mask_1_1_output_accuracy: 0.0885 - val_rws_mask_20_0_output_accuracy: 0.0987 - val_rws_mask_20_1_output_accuracy: 0.0904 - val_rws_mask_21_0_output_accuracy: 0.1000 - val_rws_mask_21_1_output_accuracy: 0.0896 - val_rws_mask_22_0_output_accuracy: 0.0974 - val_rws_mask_22_1_output_accuracy: 0.0886 - val_rws_mask_23_0_output_accuracy: 0.0922 - val_rws_mask_23_1_output_accuracy: 0.0871 - val_rws_mask_2_0_output_accuracy: 0.1000 - val_rws_mask_2_1_output_accuracy: 0.0856 - val_rws_mask_3_0_output_accuracy: 0.0841 - val_rws_mask_3_1_output_accuracy: 0.0888 - val_rws_mask_4_0_output_accuracy: 0.0831 - val_rws_mask_4_1_output_accuracy: 0.0902 - val_rws_mask_5_0_output_accuracy: 0.0954 - val_rws_mask_5_1_output_accuracy: 0.0910 - val_rws_mask_6_0_output_accuracy: 0.0856 - val_rws_mask_6_1_output_accuracy: 0.0871 - val_rws_mask_7_0_output_accuracy: 0.1013 - val_rws_mask_7_1_output_accuracy: 0.0921 - val_rws_mask_8_0_output_accuracy: 0.1043 - val_rws_mask_8_1_output_accuracy: 0.0888 - val_rws_mask_9_0_output_accuracy: 0.0991 - val_rws_mask_9_1_output_accuracy: 0.0891\n","Epoch 2/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1164s\u001b[0m 110ms/step - loss: 130.3105 - rws_mask_0_0_output_accuracy: 0.1085 - rws_mask_0_1_output_accuracy: 0.0924 - rws_mask_10_0_output_accuracy: 0.1085 - rws_mask_10_1_output_accuracy: 0.0923 - rws_mask_11_0_output_accuracy: 0.1091 - rws_mask_11_1_output_accuracy: 0.0915 - rws_mask_12_0_output_accuracy: 0.1075 - rws_mask_12_1_output_accuracy: 0.0921 - rws_mask_13_0_output_accuracy: 0.1091 - rws_mask_13_1_output_accuracy: 0.0926 - rws_mask_14_0_output_accuracy: 0.1077 - rws_mask_14_1_output_accuracy: 0.0920 - rws_mask_15_0_output_accuracy: 0.1064 - rws_mask_15_1_output_accuracy: 0.0931 - rws_mask_16_0_output_accuracy: 0.1093 - rws_mask_16_1_output_accuracy: 0.0916 - rws_mask_17_0_output_accuracy: 0.1079 - rws_mask_17_1_output_accuracy: 0.0920 - rws_mask_18_0_output_accuracy: 0.1082 - rws_mask_18_1_output_accuracy: 0.0927 - rws_mask_19_0_output_accuracy: 0.1070 - rws_mask_19_1_output_accuracy: 0.0928 - rws_mask_1_0_output_accuracy: 0.1095 - rws_mask_1_1_output_accuracy: 0.0915 - rws_mask_20_0_output_accuracy: 0.1075 - rws_mask_20_1_output_accuracy: 0.0915 - rws_mask_21_0_output_accuracy: 0.1090 - rws_mask_21_1_output_accuracy: 0.0922 - rws_mask_22_0_output_accuracy: 0.1076 - rws_mask_22_1_output_accuracy: 0.0926 - rws_mask_23_0_output_accuracy: 0.1047 - rws_mask_23_1_output_accuracy: 0.0871 - rws_mask_2_0_output_accuracy: 0.1077 - rws_mask_2_1_output_accuracy: 0.0927 - rws_mask_3_0_output_accuracy: 0.1090 - rws_mask_3_1_output_accuracy: 0.0916 - rws_mask_4_0_output_accuracy: 0.1076 - rws_mask_4_1_output_accuracy: 0.0922 - rws_mask_5_0_output_accuracy: 0.1079 - rws_mask_5_1_output_accuracy: 0.0923 - rws_mask_6_0_output_accuracy: 0.1075 - rws_mask_6_1_output_accuracy: 0.0915 - rws_mask_7_0_output_accuracy: 0.1071 - rws_mask_7_1_output_accuracy: 0.0929 - rws_mask_8_0_output_accuracy: 0.1080 - rws_mask_8_1_output_accuracy: 0.0918 - rws_mask_9_0_output_accuracy: 0.1078 - rws_mask_9_1_output_accuracy: 0.0922 - val_loss: 130.8453 - val_rws_mask_0_0_output_accuracy: 0.1045 - val_rws_mask_0_1_output_accuracy: 0.0923 - val_rws_mask_10_0_output_accuracy: 0.1014 - val_rws_mask_10_1_output_accuracy: 0.0820 - val_rws_mask_11_0_output_accuracy: 0.1060 - val_rws_mask_11_1_output_accuracy: 0.0913 - val_rws_mask_12_0_output_accuracy: 0.1036 - val_rws_mask_12_1_output_accuracy: 0.0891 - val_rws_mask_13_0_output_accuracy: 0.1058 - val_rws_mask_13_1_output_accuracy: 0.0902 - val_rws_mask_14_0_output_accuracy: 0.1029 - val_rws_mask_14_1_output_accuracy: 0.0725 - val_rws_mask_15_0_output_accuracy: 0.1031 - val_rws_mask_15_1_output_accuracy: 0.0840 - val_rws_mask_16_0_output_accuracy: 0.1061 - val_rws_mask_16_1_output_accuracy: 0.0882 - val_rws_mask_17_0_output_accuracy: 0.1060 - val_rws_mask_17_1_output_accuracy: 0.0863 - val_rws_mask_18_0_output_accuracy: 0.1061 - val_rws_mask_18_1_output_accuracy: 0.0904 - val_rws_mask_19_0_output_accuracy: 0.1045 - val_rws_mask_19_1_output_accuracy: 0.0816 - val_rws_mask_1_0_output_accuracy: 0.1007 - val_rws_mask_1_1_output_accuracy: 0.0913 - val_rws_mask_20_0_output_accuracy: 0.1008 - val_rws_mask_20_1_output_accuracy: 0.0870 - val_rws_mask_21_0_output_accuracy: 0.1050 - val_rws_mask_21_1_output_accuracy: 0.0909 - val_rws_mask_22_0_output_accuracy: 0.1047 - val_rws_mask_22_1_output_accuracy: 0.0868 - val_rws_mask_23_0_output_accuracy: 0.0978 - val_rws_mask_23_1_output_accuracy: 0.0836 - val_rws_mask_2_0_output_accuracy: 0.1068 - val_rws_mask_2_1_output_accuracy: 0.0827 - val_rws_mask_3_0_output_accuracy: 0.1053 - val_rws_mask_3_1_output_accuracy: 0.0883 - val_rws_mask_4_0_output_accuracy: 0.1036 - val_rws_mask_4_1_output_accuracy: 0.0900 - val_rws_mask_5_0_output_accuracy: 0.1011 - val_rws_mask_5_1_output_accuracy: 0.0928 - val_rws_mask_6_0_output_accuracy: 0.1048 - val_rws_mask_6_1_output_accuracy: 0.0890 - val_rws_mask_7_0_output_accuracy: 0.1050 - val_rws_mask_7_1_output_accuracy: 0.0902 - val_rws_mask_8_0_output_accuracy: 0.1068 - val_rws_mask_8_1_output_accuracy: 0.0900 - val_rws_mask_9_0_output_accuracy: 0.1040 - val_rws_mask_9_1_output_accuracy: 0.0878\n","Epoch 3/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 110ms/step - loss: 130.2801 - rws_mask_0_0_output_accuracy: 0.1081 - rws_mask_0_1_output_accuracy: 0.0930 - rws_mask_10_0_output_accuracy: 0.1094 - rws_mask_10_1_output_accuracy: 0.0925 - rws_mask_11_0_output_accuracy: 0.1094 - rws_mask_11_1_output_accuracy: 0.0928 - rws_mask_12_0_output_accuracy: 0.1082 - rws_mask_12_1_output_accuracy: 0.0927 - rws_mask_13_0_output_accuracy: 0.1091 - rws_mask_13_1_output_accuracy: 0.0932 - rws_mask_14_0_output_accuracy: 0.1079 - rws_mask_14_1_output_accuracy: 0.0928 - rws_mask_15_0_output_accuracy: 0.1076 - rws_mask_15_1_output_accuracy: 0.0924 - rws_mask_16_0_output_accuracy: 0.1091 - rws_mask_16_1_output_accuracy: 0.0920 - rws_mask_17_0_output_accuracy: 0.1077 - rws_mask_17_1_output_accuracy: 0.0928 - rws_mask_18_0_output_accuracy: 0.1091 - rws_mask_18_1_output_accuracy: 0.0932 - rws_mask_19_0_output_accuracy: 0.1086 - rws_mask_19_1_output_accuracy: 0.0928 - rws_mask_1_0_output_accuracy: 0.1081 - rws_mask_1_1_output_accuracy: 0.0916 - rws_mask_20_0_output_accuracy: 0.1077 - rws_mask_20_1_output_accuracy: 0.0927 - rws_mask_21_0_output_accuracy: 0.1096 - rws_mask_21_1_output_accuracy: 0.0931 - rws_mask_22_0_output_accuracy: 0.1075 - rws_mask_22_1_output_accuracy: 0.0922 - rws_mask_23_0_output_accuracy: 0.1048 - rws_mask_23_1_output_accuracy: 0.0875 - rws_mask_2_0_output_accuracy: 0.1071 - rws_mask_2_1_output_accuracy: 0.0922 - rws_mask_3_0_output_accuracy: 0.1098 - rws_mask_3_1_output_accuracy: 0.0927 - rws_mask_4_0_output_accuracy: 0.1074 - rws_mask_4_1_output_accuracy: 0.0923 - rws_mask_5_0_output_accuracy: 0.1077 - rws_mask_5_1_output_accuracy: 0.0928 - rws_mask_6_0_output_accuracy: 0.1081 - rws_mask_6_1_output_accuracy: 0.0919 - rws_mask_7_0_output_accuracy: 0.1076 - rws_mask_7_1_output_accuracy: 0.0926 - rws_mask_8_0_output_accuracy: 0.1087 - rws_mask_8_1_output_accuracy: 0.0922 - rws_mask_9_0_output_accuracy: 0.1075 - rws_mask_9_1_output_accuracy: 0.0922 - val_loss: 130.8408 - val_rws_mask_0_0_output_accuracy: 0.1068 - val_rws_mask_0_1_output_accuracy: 0.0920 - val_rws_mask_10_0_output_accuracy: 0.0952 - val_rws_mask_10_1_output_accuracy: 0.0869 - val_rws_mask_11_0_output_accuracy: 0.1047 - val_rws_mask_11_1_output_accuracy: 0.0907 - val_rws_mask_12_0_output_accuracy: 0.1001 - val_rws_mask_12_1_output_accuracy: 0.0908 - val_rws_mask_13_0_output_accuracy: 0.1067 - val_rws_mask_13_1_output_accuracy: 0.0919 - val_rws_mask_14_0_output_accuracy: 0.1091 - val_rws_mask_14_1_output_accuracy: 0.0892 - val_rws_mask_15_0_output_accuracy: 0.0999 - val_rws_mask_15_1_output_accuracy: 0.0883 - val_rws_mask_16_0_output_accuracy: 0.1041 - val_rws_mask_16_1_output_accuracy: 0.0845 - val_rws_mask_17_0_output_accuracy: 0.1043 - val_rws_mask_17_1_output_accuracy: 0.0866 - val_rws_mask_18_0_output_accuracy: 0.1068 - val_rws_mask_18_1_output_accuracy: 0.0891 - val_rws_mask_19_0_output_accuracy: 0.1024 - val_rws_mask_19_1_output_accuracy: 0.0926 - val_rws_mask_1_0_output_accuracy: 0.1018 - val_rws_mask_1_1_output_accuracy: 0.0919 - val_rws_mask_20_0_output_accuracy: 0.0998 - val_rws_mask_20_1_output_accuracy: 0.0862 - val_rws_mask_21_0_output_accuracy: 0.1042 - val_rws_mask_21_1_output_accuracy: 0.0862 - val_rws_mask_22_0_output_accuracy: 0.1054 - val_rws_mask_22_1_output_accuracy: 0.0874 - val_rws_mask_23_0_output_accuracy: 0.0994 - val_rws_mask_23_1_output_accuracy: 0.0852 - val_rws_mask_2_0_output_accuracy: 0.1024 - val_rws_mask_2_1_output_accuracy: 0.0867 - val_rws_mask_3_0_output_accuracy: 0.0999 - val_rws_mask_3_1_output_accuracy: 0.0885 - val_rws_mask_4_0_output_accuracy: 0.1034 - val_rws_mask_4_1_output_accuracy: 0.0918 - val_rws_mask_5_0_output_accuracy: 0.1064 - val_rws_mask_5_1_output_accuracy: 0.0921 - val_rws_mask_6_0_output_accuracy: 0.1055 - val_rws_mask_6_1_output_accuracy: 0.0912 - val_rws_mask_7_0_output_accuracy: 0.1000 - val_rws_mask_7_1_output_accuracy: 0.0877 - val_rws_mask_8_0_output_accuracy: 0.1049 - val_rws_mask_8_1_output_accuracy: 0.0850 - val_rws_mask_9_0_output_accuracy: 0.1042 - val_rws_mask_9_1_output_accuracy: 0.0900\n","Epoch 4/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1157s\u001b[0m 110ms/step - loss: 130.2494 - rws_mask_0_0_output_accuracy: 0.1083 - rws_mask_0_1_output_accuracy: 0.0927 - rws_mask_10_0_output_accuracy: 0.1092 - rws_mask_10_1_output_accuracy: 0.0928 - rws_mask_11_0_output_accuracy: 0.1095 - rws_mask_11_1_output_accuracy: 0.0931 - rws_mask_12_0_output_accuracy: 0.1081 - rws_mask_12_1_output_accuracy: 0.0929 - rws_mask_13_0_output_accuracy: 0.1096 - rws_mask_13_1_output_accuracy: 0.0920 - rws_mask_14_0_output_accuracy: 0.1082 - rws_mask_14_1_output_accuracy: 0.0926 - rws_mask_15_0_output_accuracy: 0.1079 - rws_mask_15_1_output_accuracy: 0.0929 - rws_mask_16_0_output_accuracy: 0.1097 - rws_mask_16_1_output_accuracy: 0.0926 - rws_mask_17_0_output_accuracy: 0.1087 - rws_mask_17_1_output_accuracy: 0.0933 - rws_mask_18_0_output_accuracy: 0.1092 - rws_mask_18_1_output_accuracy: 0.0935 - rws_mask_19_0_output_accuracy: 0.1092 - rws_mask_19_1_output_accuracy: 0.0941 - rws_mask_1_0_output_accuracy: 0.1090 - rws_mask_1_1_output_accuracy: 0.0925 - rws_mask_20_0_output_accuracy: 0.1068 - rws_mask_20_1_output_accuracy: 0.0929 - rws_mask_21_0_output_accuracy: 0.1095 - rws_mask_21_1_output_accuracy: 0.0931 - rws_mask_22_0_output_accuracy: 0.1087 - rws_mask_22_1_output_accuracy: 0.0927 - rws_mask_23_0_output_accuracy: 0.1062 - rws_mask_23_1_output_accuracy: 0.0884 - rws_mask_2_0_output_accuracy: 0.1071 - rws_mask_2_1_output_accuracy: 0.0934 - rws_mask_3_0_output_accuracy: 0.1101 - rws_mask_3_1_output_accuracy: 0.0924 - rws_mask_4_0_output_accuracy: 0.1077 - rws_mask_4_1_output_accuracy: 0.0925 - rws_mask_5_0_output_accuracy: 0.1085 - rws_mask_5_1_output_accuracy: 0.0924 - rws_mask_6_0_output_accuracy: 0.1089 - rws_mask_6_1_output_accuracy: 0.0920 - rws_mask_7_0_output_accuracy: 0.1072 - rws_mask_7_1_output_accuracy: 0.0928 - rws_mask_8_0_output_accuracy: 0.1090 - rws_mask_8_1_output_accuracy: 0.0921 - rws_mask_9_0_output_accuracy: 0.1075 - rws_mask_9_1_output_accuracy: 0.0928 - val_loss: 130.6529 - val_rws_mask_0_0_output_accuracy: 0.1048 - val_rws_mask_0_1_output_accuracy: 0.0874 - val_rws_mask_10_0_output_accuracy: 0.1052 - val_rws_mask_10_1_output_accuracy: 0.0904 - val_rws_mask_11_0_output_accuracy: 0.1048 - val_rws_mask_11_1_output_accuracy: 0.0883 - val_rws_mask_12_0_output_accuracy: 0.1068 - val_rws_mask_12_1_output_accuracy: 0.0919 - val_rws_mask_13_0_output_accuracy: 0.1069 - val_rws_mask_13_1_output_accuracy: 0.0912 - val_rws_mask_14_0_output_accuracy: 0.1029 - val_rws_mask_14_1_output_accuracy: 0.0877 - val_rws_mask_15_0_output_accuracy: 0.1055 - val_rws_mask_15_1_output_accuracy: 0.0913 - val_rws_mask_16_0_output_accuracy: 0.1066 - val_rws_mask_16_1_output_accuracy: 0.0819 - val_rws_mask_17_0_output_accuracy: 0.0991 - val_rws_mask_17_1_output_accuracy: 0.0862 - val_rws_mask_18_0_output_accuracy: 0.1062 - val_rws_mask_18_1_output_accuracy: 0.0906 - val_rws_mask_19_0_output_accuracy: 0.1071 - val_rws_mask_19_1_output_accuracy: 0.0912 - val_rws_mask_1_0_output_accuracy: 0.1073 - val_rws_mask_1_1_output_accuracy: 0.0896 - val_rws_mask_20_0_output_accuracy: 0.1024 - val_rws_mask_20_1_output_accuracy: 0.0894 - val_rws_mask_21_0_output_accuracy: 0.1056 - val_rws_mask_21_1_output_accuracy: 0.0920 - val_rws_mask_22_0_output_accuracy: 0.1044 - val_rws_mask_22_1_output_accuracy: 0.0876 - val_rws_mask_23_0_output_accuracy: 0.1035 - val_rws_mask_23_1_output_accuracy: 0.0871 - val_rws_mask_2_0_output_accuracy: 0.1000 - val_rws_mask_2_1_output_accuracy: 0.0922 - val_rws_mask_3_0_output_accuracy: 0.1062 - val_rws_mask_3_1_output_accuracy: 0.0887 - val_rws_mask_4_0_output_accuracy: 0.1039 - val_rws_mask_4_1_output_accuracy: 0.0897 - val_rws_mask_5_0_output_accuracy: 0.1062 - val_rws_mask_5_1_output_accuracy: 0.0943 - val_rws_mask_6_0_output_accuracy: 0.1043 - val_rws_mask_6_1_output_accuracy: 0.0923 - val_rws_mask_7_0_output_accuracy: 0.1077 - val_rws_mask_7_1_output_accuracy: 0.0900 - val_rws_mask_8_0_output_accuracy: 0.1060 - val_rws_mask_8_1_output_accuracy: 0.0917 - val_rws_mask_9_0_output_accuracy: 0.1028 - val_rws_mask_9_1_output_accuracy: 0.0899\n","Epoch 5/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1142s\u001b[0m 108ms/step - loss: 130.2227 - rws_mask_0_0_output_accuracy: 0.1089 - rws_mask_0_1_output_accuracy: 0.0930 - rws_mask_10_0_output_accuracy: 0.1095 - rws_mask_10_1_output_accuracy: 0.0920 - rws_mask_11_0_output_accuracy: 0.1102 - rws_mask_11_1_output_accuracy: 0.0931 - rws_mask_12_0_output_accuracy: 0.1084 - rws_mask_12_1_output_accuracy: 0.0928 - rws_mask_13_0_output_accuracy: 0.1098 - rws_mask_13_1_output_accuracy: 0.0935 - rws_mask_14_0_output_accuracy: 0.1091 - rws_mask_14_1_output_accuracy: 0.0931 - rws_mask_15_0_output_accuracy: 0.1084 - rws_mask_15_1_output_accuracy: 0.0946 - rws_mask_16_0_output_accuracy: 0.1102 - rws_mask_16_1_output_accuracy: 0.0930 - rws_mask_17_0_output_accuracy: 0.1084 - rws_mask_17_1_output_accuracy: 0.0935 - rws_mask_18_0_output_accuracy: 0.1097 - rws_mask_18_1_output_accuracy: 0.0931 - rws_mask_19_0_output_accuracy: 0.1096 - rws_mask_19_1_output_accuracy: 0.0936 - rws_mask_1_0_output_accuracy: 0.1090 - rws_mask_1_1_output_accuracy: 0.0924 - rws_mask_20_0_output_accuracy: 0.1080 - rws_mask_20_1_output_accuracy: 0.0923 - rws_mask_21_0_output_accuracy: 0.1097 - rws_mask_21_1_output_accuracy: 0.0929 - rws_mask_22_0_output_accuracy: 0.1083 - rws_mask_22_1_output_accuracy: 0.0934 - rws_mask_23_0_output_accuracy: 0.1064 - rws_mask_23_1_output_accuracy: 0.0886 - rws_mask_2_0_output_accuracy: 0.1075 - rws_mask_2_1_output_accuracy: 0.0930 - rws_mask_3_0_output_accuracy: 0.1103 - rws_mask_3_1_output_accuracy: 0.0932 - rws_mask_4_0_output_accuracy: 0.1086 - rws_mask_4_1_output_accuracy: 0.0930 - rws_mask_5_0_output_accuracy: 0.1081 - rws_mask_5_1_output_accuracy: 0.0928 - rws_mask_6_0_output_accuracy: 0.1093 - rws_mask_6_1_output_accuracy: 0.0926 - rws_mask_7_0_output_accuracy: 0.1077 - rws_mask_7_1_output_accuracy: 0.0931 - rws_mask_8_0_output_accuracy: 0.1095 - rws_mask_8_1_output_accuracy: 0.0925 - rws_mask_9_0_output_accuracy: 0.1083 - rws_mask_9_1_output_accuracy: 0.0929 - val_loss: 131.2933 - val_rws_mask_0_0_output_accuracy: 0.0937 - val_rws_mask_0_1_output_accuracy: 0.0841 - val_rws_mask_10_0_output_accuracy: 0.1018 - val_rws_mask_10_1_output_accuracy: 0.0901 - val_rws_mask_11_0_output_accuracy: 0.1075 - val_rws_mask_11_1_output_accuracy: 0.0815 - val_rws_mask_12_0_output_accuracy: 0.0931 - val_rws_mask_12_1_output_accuracy: 0.0858 - val_rws_mask_13_0_output_accuracy: 0.1029 - val_rws_mask_13_1_output_accuracy: 0.0899 - val_rws_mask_14_0_output_accuracy: 0.1029 - val_rws_mask_14_1_output_accuracy: 0.0879 - val_rws_mask_15_0_output_accuracy: 0.0994 - val_rws_mask_15_1_output_accuracy: 0.0897 - val_rws_mask_16_0_output_accuracy: 0.1067 - val_rws_mask_16_1_output_accuracy: 0.0876 - val_rws_mask_17_0_output_accuracy: 0.1031 - val_rws_mask_17_1_output_accuracy: 0.0861 - val_rws_mask_18_0_output_accuracy: 0.1053 - val_rws_mask_18_1_output_accuracy: 0.0910 - val_rws_mask_19_0_output_accuracy: 0.1048 - val_rws_mask_19_1_output_accuracy: 0.0814 - val_rws_mask_1_0_output_accuracy: 0.1027 - val_rws_mask_1_1_output_accuracy: 0.0895 - val_rws_mask_20_0_output_accuracy: 0.0945 - val_rws_mask_20_1_output_accuracy: 0.0925 - val_rws_mask_21_0_output_accuracy: 0.0969 - val_rws_mask_21_1_output_accuracy: 0.0859 - val_rws_mask_22_0_output_accuracy: 0.1009 - val_rws_mask_22_1_output_accuracy: 0.0795 - val_rws_mask_23_0_output_accuracy: 0.0993 - val_rws_mask_23_1_output_accuracy: 0.0870 - val_rws_mask_2_0_output_accuracy: 0.1037 - val_rws_mask_2_1_output_accuracy: 0.0880 - val_rws_mask_3_0_output_accuracy: 0.1079 - val_rws_mask_3_1_output_accuracy: 0.0839 - val_rws_mask_4_0_output_accuracy: 0.0969 - val_rws_mask_4_1_output_accuracy: 0.0897 - val_rws_mask_5_0_output_accuracy: 0.0951 - val_rws_mask_5_1_output_accuracy: 0.0897 - val_rws_mask_6_0_output_accuracy: 0.1035 - val_rws_mask_6_1_output_accuracy: 0.0813 - val_rws_mask_7_0_output_accuracy: 0.0950 - val_rws_mask_7_1_output_accuracy: 0.0878 - val_rws_mask_8_0_output_accuracy: 0.1019 - val_rws_mask_8_1_output_accuracy: 0.0906 - val_rws_mask_9_0_output_accuracy: 0.0977 - val_rws_mask_9_1_output_accuracy: 0.0793\n","Epoch 6/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1140s\u001b[0m 108ms/step - loss: 130.2033 - rws_mask_0_0_output_accuracy: 0.1096 - rws_mask_0_1_output_accuracy: 0.0935 - rws_mask_10_0_output_accuracy: 0.1103 - rws_mask_10_1_output_accuracy: 0.0935 - rws_mask_11_0_output_accuracy: 0.1093 - rws_mask_11_1_output_accuracy: 0.0934 - rws_mask_12_0_output_accuracy: 0.1088 - rws_mask_12_1_output_accuracy: 0.0934 - rws_mask_13_0_output_accuracy: 0.1103 - rws_mask_13_1_output_accuracy: 0.0934 - rws_mask_14_0_output_accuracy: 0.1081 - rws_mask_14_1_output_accuracy: 0.0930 - rws_mask_15_0_output_accuracy: 0.1080 - rws_mask_15_1_output_accuracy: 0.0929 - rws_mask_16_0_output_accuracy: 0.1111 - rws_mask_16_1_output_accuracy: 0.0932 - rws_mask_17_0_output_accuracy: 0.1081 - rws_mask_17_1_output_accuracy: 0.0936 - rws_mask_18_0_output_accuracy: 0.1094 - rws_mask_18_1_output_accuracy: 0.0943 - rws_mask_19_0_output_accuracy: 0.1087 - rws_mask_19_1_output_accuracy: 0.0930 - rws_mask_1_0_output_accuracy: 0.1093 - rws_mask_1_1_output_accuracy: 0.0930 - rws_mask_20_0_output_accuracy: 0.1081 - rws_mask_20_1_output_accuracy: 0.0929 - rws_mask_21_0_output_accuracy: 0.1098 - rws_mask_21_1_output_accuracy: 0.0936 - rws_mask_22_0_output_accuracy: 0.1086 - rws_mask_22_1_output_accuracy: 0.0939 - rws_mask_23_0_output_accuracy: 0.1056 - rws_mask_23_1_output_accuracy: 0.0900 - rws_mask_2_0_output_accuracy: 0.1078 - rws_mask_2_1_output_accuracy: 0.0931 - rws_mask_3_0_output_accuracy: 0.1106 - rws_mask_3_1_output_accuracy: 0.0931 - rws_mask_4_0_output_accuracy: 0.1083 - rws_mask_4_1_output_accuracy: 0.0929 - rws_mask_5_0_output_accuracy: 0.1087 - rws_mask_5_1_output_accuracy: 0.0935 - rws_mask_6_0_output_accuracy: 0.1098 - rws_mask_6_1_output_accuracy: 0.0925 - rws_mask_7_0_output_accuracy: 0.1073 - rws_mask_7_1_output_accuracy: 0.0933 - rws_mask_8_0_output_accuracy: 0.1094 - rws_mask_8_1_output_accuracy: 0.0915 - rws_mask_9_0_output_accuracy: 0.1095 - rws_mask_9_1_output_accuracy: 0.0930 - val_loss: 130.7320 - val_rws_mask_0_0_output_accuracy: 0.1049 - val_rws_mask_0_1_output_accuracy: 0.0908 - val_rws_mask_10_0_output_accuracy: 0.1031 - val_rws_mask_10_1_output_accuracy: 0.0915 - val_rws_mask_11_0_output_accuracy: 0.1057 - val_rws_mask_11_1_output_accuracy: 0.0905 - val_rws_mask_12_0_output_accuracy: 0.1030 - val_rws_mask_12_1_output_accuracy: 0.0859 - val_rws_mask_13_0_output_accuracy: 0.1093 - val_rws_mask_13_1_output_accuracy: 0.0887 - val_rws_mask_14_0_output_accuracy: 0.1063 - val_rws_mask_14_1_output_accuracy: 0.0823 - val_rws_mask_15_0_output_accuracy: 0.1074 - val_rws_mask_15_1_output_accuracy: 0.0895 - val_rws_mask_16_0_output_accuracy: 0.0988 - val_rws_mask_16_1_output_accuracy: 0.0901 - val_rws_mask_17_0_output_accuracy: 0.1012 - val_rws_mask_17_1_output_accuracy: 0.0829 - val_rws_mask_18_0_output_accuracy: 0.1061 - val_rws_mask_18_1_output_accuracy: 0.0907 - val_rws_mask_19_0_output_accuracy: 0.1012 - val_rws_mask_19_1_output_accuracy: 0.0898 - val_rws_mask_1_0_output_accuracy: 0.1047 - val_rws_mask_1_1_output_accuracy: 0.0895 - val_rws_mask_20_0_output_accuracy: 0.1067 - val_rws_mask_20_1_output_accuracy: 0.0928 - val_rws_mask_21_0_output_accuracy: 0.1048 - val_rws_mask_21_1_output_accuracy: 0.0915 - val_rws_mask_22_0_output_accuracy: 0.1036 - val_rws_mask_22_1_output_accuracy: 0.0899 - val_rws_mask_23_0_output_accuracy: 0.1027 - val_rws_mask_23_1_output_accuracy: 0.0853 - val_rws_mask_2_0_output_accuracy: 0.1035 - val_rws_mask_2_1_output_accuracy: 0.0902 - val_rws_mask_3_0_output_accuracy: 0.1060 - val_rws_mask_3_1_output_accuracy: 0.0877 - val_rws_mask_4_0_output_accuracy: 0.1036 - val_rws_mask_4_1_output_accuracy: 0.0916 - val_rws_mask_5_0_output_accuracy: 0.1058 - val_rws_mask_5_1_output_accuracy: 0.0868 - val_rws_mask_6_0_output_accuracy: 0.1075 - val_rws_mask_6_1_output_accuracy: 0.0928 - val_rws_mask_7_0_output_accuracy: 0.1069 - val_rws_mask_7_1_output_accuracy: 0.0930 - val_rws_mask_8_0_output_accuracy: 0.1074 - val_rws_mask_8_1_output_accuracy: 0.0869 - val_rws_mask_9_0_output_accuracy: 0.0938 - val_rws_mask_9_1_output_accuracy: 0.0913\n","Epoch 7/1000\n","\u001b[1m10547/10547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1155s\u001b[0m 109ms/step - loss: 130.1842 - rws_mask_0_0_output_accuracy: 0.1098 - rws_mask_0_1_output_accuracy: 0.0931 - rws_mask_10_0_output_accuracy: 0.1103 - rws_mask_10_1_output_accuracy: 0.0938 - rws_mask_11_0_output_accuracy: 0.1102 - rws_mask_11_1_output_accuracy: 0.0937 - rws_mask_12_0_output_accuracy: 0.1093 - rws_mask_12_1_output_accuracy: 0.0941 - rws_mask_13_0_output_accuracy: 0.1101 - rws_mask_13_1_output_accuracy: 0.0932 - rws_mask_14_0_output_accuracy: 0.1096 - rws_mask_14_1_output_accuracy: 0.0932 - rws_mask_15_0_output_accuracy: 0.1084 - rws_mask_15_1_output_accuracy: 0.0939 - rws_mask_16_0_output_accuracy: 0.1109 - rws_mask_16_1_output_accuracy: 0.0938 - rws_mask_17_0_output_accuracy: 0.1083 - rws_mask_17_1_output_accuracy: 0.0929 - rws_mask_18_0_output_accuracy: 0.1097 - rws_mask_18_1_output_accuracy: 0.0941 - rws_mask_19_0_output_accuracy: 0.1100 - rws_mask_19_1_output_accuracy: 0.0942 - rws_mask_1_0_output_accuracy: 0.1094 - rws_mask_1_1_output_accuracy: 0.0933 - rws_mask_20_0_output_accuracy: 0.1080 - rws_mask_20_1_output_accuracy: 0.0928 - rws_mask_21_0_output_accuracy: 0.1091 - rws_mask_21_1_output_accuracy: 0.0943 - rws_mask_22_0_output_accuracy: 0.1096 - rws_mask_22_1_output_accuracy: 0.0940 - rws_mask_23_0_output_accuracy: 0.1061 - rws_mask_23_1_output_accuracy: 0.0888 - rws_mask_2_0_output_accuracy: 0.1082 - rws_mask_2_1_output_accuracy: 0.0939 - rws_mask_3_0_output_accuracy: 0.1108 - rws_mask_3_1_output_accuracy: 0.0930 - rws_mask_4_0_output_accuracy: 0.1089 - rws_mask_4_1_output_accuracy: 0.0931 - rws_mask_5_0_output_accuracy: 0.1084 - rws_mask_5_1_output_accuracy: 0.0942 - rws_mask_6_0_output_accuracy: 0.1096 - rws_mask_6_1_output_accuracy: 0.0927 - rws_mask_7_0_output_accuracy: 0.1089 - rws_mask_7_1_output_accuracy: 0.0934 - rws_mask_8_0_output_accuracy: 0.1098 - rws_mask_8_1_output_accuracy: 0.0933 - rws_mask_9_0_output_accuracy: 0.1088 - rws_mask_9_1_output_accuracy: 0.0933 - val_loss: 130.9189 - val_rws_mask_0_0_output_accuracy: 0.1032 - val_rws_mask_0_1_output_accuracy: 0.0894 - val_rws_mask_10_0_output_accuracy: 0.0961 - val_rws_mask_10_1_output_accuracy: 0.0865 - val_rws_mask_11_0_output_accuracy: 0.1053 - val_rws_mask_11_1_output_accuracy: 0.0910 - val_rws_mask_12_0_output_accuracy: 0.1040 - val_rws_mask_12_1_output_accuracy: 0.0918 - val_rws_mask_13_0_output_accuracy: 0.1018 - val_rws_mask_13_1_output_accuracy: 0.0899 - val_rws_mask_14_0_output_accuracy: 0.1045 - val_rws_mask_14_1_output_accuracy: 0.0892 - val_rws_mask_15_0_output_accuracy: 0.0968 - val_rws_mask_15_1_output_accuracy: 0.0891 - val_rws_mask_16_0_output_accuracy: 0.1077 - val_rws_mask_16_1_output_accuracy: 0.0901 - val_rws_mask_17_0_output_accuracy: 0.1040 - val_rws_mask_17_1_output_accuracy: 0.0883 - val_rws_mask_18_0_output_accuracy: 0.1002 - val_rws_mask_18_1_output_accuracy: 0.0895 - val_rws_mask_19_0_output_accuracy: 0.1034 - val_rws_mask_19_1_output_accuracy: 0.0911 - val_rws_mask_1_0_output_accuracy: 0.0975 - val_rws_mask_1_1_output_accuracy: 0.0903 - val_rws_mask_20_0_output_accuracy: 0.0945 - val_rws_mask_20_1_output_accuracy: 0.0829 - val_rws_mask_21_0_output_accuracy: 0.1017 - val_rws_mask_21_1_output_accuracy: 0.0903 - val_rws_mask_22_0_output_accuracy: 0.1026 - val_rws_mask_22_1_output_accuracy: 0.0878 - val_rws_mask_23_0_output_accuracy: 0.0995 - val_rws_mask_23_1_output_accuracy: 0.0835 - val_rws_mask_2_0_output_accuracy: 0.1057 - val_rws_mask_2_1_output_accuracy: 0.0885 - val_rws_mask_3_0_output_accuracy: 0.1028 - val_rws_mask_3_1_output_accuracy: 0.0911 - val_rws_mask_4_0_output_accuracy: 0.1047 - val_rws_mask_4_1_output_accuracy: 0.0898 - val_rws_mask_5_0_output_accuracy: 0.1021 - val_rws_mask_5_1_output_accuracy: 0.0908 - val_rws_mask_6_0_output_accuracy: 0.1018 - val_rws_mask_6_1_output_accuracy: 0.0909 - val_rws_mask_7_0_output_accuracy: 0.0932 - val_rws_mask_7_1_output_accuracy: 0.0929 - val_rws_mask_8_0_output_accuracy: 0.0987 - val_rws_mask_8_1_output_accuracy: 0.0896 - val_rws_mask_9_0_output_accuracy: 0.1035 - val_rws_mask_9_1_output_accuracy: 0.0898\n","Epoch 8/1000\n","\u001b[1m 2583/10547\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14:14\u001b[0m 107ms/step - loss: 130.1413 - rws_mask_0_0_output_accuracy: 0.1087 - rws_mask_0_1_output_accuracy: 0.0910 - rws_mask_10_0_output_accuracy: 0.1099 - rws_mask_10_1_output_accuracy: 0.0943 - rws_mask_11_0_output_accuracy: 0.1090 - rws_mask_11_1_output_accuracy: 0.0947 - rws_mask_12_0_output_accuracy: 0.1078 - rws_mask_12_1_output_accuracy: 0.0938 - rws_mask_13_0_output_accuracy: 0.1108 - rws_mask_13_1_output_accuracy: 0.0957 - rws_mask_14_0_output_accuracy: 0.1097 - rws_mask_14_1_output_accuracy: 0.0936 - rws_mask_15_0_output_accuracy: 0.1079 - rws_mask_15_1_output_accuracy: 0.0932 - rws_mask_16_0_output_accuracy: 0.1107 - rws_mask_16_1_output_accuracy: 0.0937 - rws_mask_17_0_output_accuracy: 0.1100 - rws_mask_17_1_output_accuracy: 0.0927 - rws_mask_18_0_output_accuracy: 0.1112 - rws_mask_18_1_output_accuracy: 0.0922 - rws_mask_19_0_output_accuracy: 0.1109 - rws_mask_19_1_output_accuracy: 0.0931 - rws_mask_1_0_output_accuracy: 0.1105 - rws_mask_1_1_output_accuracy: 0.0931 - rws_mask_20_0_output_accuracy: 0.1080 - rws_mask_20_1_output_accuracy: 0.0933 - rws_mask_21_0_output_accuracy: 0.1093 - rws_mask_21_1_output_accuracy: 0.0949 - rws_mask_22_0_output_accuracy: 0.1090 - rws_mask_22_1_output_accuracy: 0.0936 - rws_mask_23_0_output_accuracy: 0.1099 - rws_mask_23_1_output_accuracy: 0.0900 - rws_mask_2_0_output_accuracy: 0.1112 - rws_mask_2_1_output_accuracy: 0.0947 - rws_mask_3_0_output_accuracy: 0.1125 - rws_mask_3_1_output_accuracy: 0.0928 - rws_mask_4_0_output_accuracy: 0.1090 - rws_mask_4_1_output_accuracy: 0.0945 - rws_mask_5_0_output_accuracy: 0.1093 - rws_mask_5_1_output_accuracy: 0.0964 - rws_mask_6_0_output_accuracy: 0.1099 - rws_mask_6_1_output_accuracy: 0.0934 - rws_mask_7_0_output_accuracy: 0.1103 - rws_mask_7_1_output_accuracy: 0.0927 - rws_mask_8_0_output_accuracy: 0.1110 - rws_mask_8_1_output_accuracy: 0.0928 - rws_mask_9_0_output_accuracy: 0.1090 - rws_mask_9_1_output_accuracy: 0.0948"]}],"source":["history = resnet.train_model_generator(train_gen, val_gen, \"./resnet_models/resnet_750000_orig_rws_2.keras\", patience=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
